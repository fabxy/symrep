{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2022 Flatiron Machine Learning x Science Summer School\n",
    "\n",
    "## Step 2: Run symbolic regression on generic data\n",
    "\n",
    "In this step, we investigate whether symbolic regression can discover the functions underlying the generic data created in Step 1. There is no support from deep learning at this point.\n",
    "\n",
    "We use the symbolic regression package [PySR](https://github.com/MilesCranmer/PySR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "from pysr import PySRRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.1: Load data\n",
    "\n",
    "We load the input and target function data created in Step 1 and create masks to split the data into training, validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data_1k\"\n",
    "data_ext = \".gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded F00 data.\n",
      "Loaded F01 data.\n",
      "Loaded F02 data.\n",
      "Loaded F03 data.\n",
      "Loaded F04 data.\n",
      "Loaded F05 data.\n",
      "Loaded F06 data.\n",
      "Loaded G00 data.\n",
      "Loaded G01 data.\n",
      "Loaded G02 data.\n",
      "Loaded G03 data.\n",
      "Loaded G04 data.\n",
      "Loaded G05 data.\n",
      "Loaded G06 data.\n",
      "Loaded X00 data.\n",
      "Loaded X01 data.\n",
      "Loaded X02 data.\n",
      "Loaded X03 data.\n",
      "Loaded X04 data.\n",
      "Loaded X05 data.\n",
      "Loaded X06 data.\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "for file_name in os.listdir(data_path):\n",
    "    if file_name[-len(data_ext):] == data_ext:\n",
    "        \n",
    "        var = file_name[:-len(data_ext)]\n",
    "        var_data = np.loadtxt(os.path.join(data_path, file_name))\n",
    "        if len(var_data.shape) == 1:\n",
    "            var_data = var_data.reshape(-1,1)\n",
    "        data[var] = var_data\n",
    "\n",
    "        print(f\"Loaded {var} data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "\n",
    "train_size = 0.7\n",
    "val_size = 0.2\n",
    "\n",
    "mask_ext = \".mask\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded masks for X00 data.\n",
      "Loaded masks for X01 data.\n",
      "Loaded masks for X02 data.\n",
      "Loaded masks for X03 data.\n",
      "Loaded masks for X04 data.\n",
      "Loaded masks for X05 data.\n",
      "Created masks for X06 data.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "\n",
    "masks = {}\n",
    "for var in data:\n",
    "    if var[0] == \"X\":\n",
    "\n",
    "        mask_name = var + mask_ext\n",
    "        try:\n",
    "            masks[var] = joblib.load(os.path.join(data_path, mask_name))\n",
    "            print(f\"Loaded masks for {var} data.\")\n",
    "        except:\n",
    "            data_size = data[var].shape[0]\n",
    "\n",
    "            data_idx = np.arange(data_size)\n",
    "            np.random.shuffle(data_idx)\n",
    "\n",
    "            train_idx = int(data_size*train_size)\n",
    "            val_idx = train_idx + int(data_size*val_size)\n",
    "\n",
    "            masks[var] = {\n",
    "                \"train\": data_idx[:train_idx],\n",
    "                \"val\": data_idx[train_idx:val_idx],\n",
    "                \"test\": data_idx[val_idx:],\n",
    "            }\n",
    "    \n",
    "            joblib.dump(masks[var], os.path.join(data_path, mask_name))\n",
    "\n",
    "            print(f\"Created masks for {var} data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.2: Run PySR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(X, y):\n",
    "\n",
    "    model = PySRRegressor(\n",
    "        procs=4,\n",
    "        populations=30,\n",
    "        niterations=30,\n",
    "        maxsize=20,\n",
    "        binary_operators=[\"plus\", \"sub\", \"mult\"],\n",
    "        unary_operators=[\"sin\", \"cos\", \"exp\", \"log_abs\"],      \n",
    "        model_selection=\"best\",\n",
    "        verbosity=0\n",
    "    )\n",
    "\n",
    "    model.fit(X, y)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"models\"\n",
    "model_name = \"pysr_models_1k.pkl\"\n",
    "\n",
    "try:\n",
    "    models = joblib.load(os.path.join(model_path, model_name))\n",
    "except:\n",
    "    models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning F06_0(G06).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: ignoring conflicting import of CoreModule.div into SymbolicRegression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning F06_0(X06).\n",
      "Learning G06_0(X06).\n",
      "Learning G06_1(X06).\n",
      "Learning G06_2(X06).\n"
     ]
    }
   ],
   "source": [
    "for var in sorted([k for k in data.keys() if k[0] == \"F\" and k not in models]):\n",
    "\n",
    "    # get target dimensions\n",
    "    f_dim = data[var].shape[1]\n",
    "\n",
    "    # get input variables\n",
    "    g_var = \"G\" + var[1:]        \n",
    "    x_var = \"X\" + var[1:]\n",
    "    while x_var not in data:\n",
    "        x_num = int(x_var[1:]) - 1\n",
    "        if x_num == 0:\n",
    "            raise RuntimeError(\"Input data not loaded.\")\n",
    "        x_var = f\"X{x_num:02d}\"\n",
    "\n",
    "    # get training mask\n",
    "    mask = masks[x_var][\"train\"]\n",
    "\n",
    "    models[var] = {g_var: [], x_var: []}\n",
    "    for i in range(f_dim):\n",
    "\n",
    "        # get target data\n",
    "        y = data[var][mask,i]\n",
    "\n",
    "        # learn f(x)\n",
    "        print(f\"Learning {var}_{i}({g_var}).\")\n",
    "        X = data[g_var][mask]\n",
    "        models[var][g_var].append(get_model(X, y))\n",
    "\n",
    "        joblib.dump(models, os.path.join(model_path, model_name))\n",
    "    \n",
    "        # learn f(g(x))\n",
    "        print(f\"Learning {var}_{i}({x_var}).\")\n",
    "        X = data[x_var][mask]\n",
    "        models[var][x_var].append(get_model(X, y))\n",
    "\n",
    "        joblib.dump(models, os.path.join(model_path, model_name))\n",
    "\n",
    "    # get target dimensions\n",
    "    g_dim = data[g_var].shape[1]\n",
    "\n",
    "    models[g_var] = {x_var: []}\n",
    "    for i in range(g_dim):\n",
    "\n",
    "        # get target data\n",
    "        y = data[g_var][mask,i]\n",
    "   \n",
    "        # learn g(x)\n",
    "        print(f\"Learning {g_var}_{i}({x_var}).\")\n",
    "        X = data[x_var][mask]\n",
    "        models[g_var][x_var].append(get_model(X, y))\n",
    "\n",
    "        joblib.dump(models, os.path.join(model_path, model_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted hall_of_fame_2022-07-06_153943.547.csv.\n",
      "Deleted hall_of_fame_2022-07-06_153943.547.csv.bkup.\n",
      "Deleted hall_of_fame_2022-07-06_154626.996.csv.\n",
      "Deleted hall_of_fame_2022-07-06_154626.996.csv.bkup.\n",
      "Deleted hall_of_fame_2022-07-06_154856.204.csv.\n",
      "Deleted hall_of_fame_2022-07-06_154856.204.csv.bkup.\n",
      "Deleted hall_of_fame_2022-07-06_155048.173.csv.\n",
      "Deleted hall_of_fame_2022-07-06_155048.173.csv.bkup.\n",
      "Deleted hall_of_fame_2022-07-06_155242.793.csv.\n",
      "Deleted hall_of_fame_2022-07-06_155242.793.csv.bkup.\n"
     ]
    }
   ],
   "source": [
    "del_name = \"hall_of_fame_\"\n",
    "\n",
    "for f in os.listdir():\n",
    "    if del_name in f:\n",
    "        os.remove(f)\n",
    "        print(f\"Deleted {f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.3: Check discovery\n",
    "\n",
    "We check whether models were identified correctly based on the PySR loss. More advanced checks could consider the validation data or out-of-distribution data, as the correct model would both generalize and extrapolate accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_eps = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F01_0(G01): 1.27e-12 - [X] - ((x0 * x0) + x0)\n",
      "F01_0(X01): 6.42e+00 - [ ] - exp(log_abs(((x0 * x0) * (x0 + x1)) * 3.936279))\n",
      "G01_0(X01): 1.86e-14 - [X] - ((x0 * (x0 + x1)) + cos(x1))\n",
      "F02_0(G02): 6.87e-12 - [X] - (((x0 + x1) - (-1.0 - x2)) * ((x0 + x1) + x2))\n",
      "F02_0(X02): 1.91e+01 - [ ] - ((exp(x0 - -0.66884756) - exp(0.56625456 - x0)) * (x0 + x1))\n",
      "G02_0(X02): 9.49e-15 - [X] - (x0 * x0)\n",
      "G02_1(X02): 7.52e-16 - [X] - cos(x1)\n",
      "G02_2(X02): 2.82e-15 - [X] - (x1 * x0)\n",
      "F03_0(G03): 4.49e-11 - [X] - (x0 * (x0 + 2.7449996))\n",
      "F03_0(X03): 9.09e+02 - [ ] - exp(x2 * 2.6428516)\n",
      "G03_0(X03): 1.87e-13 - [X] - ((exp(x2) + ((x2 * x2) * x2)) + (cos(x1) * sin(x0)))\n",
      "F04_0(G04): 8.81e-13 - [X] - ((x1 * x2) + (x0 * x0))\n",
      "F04_0(X04): 8.51e+00 - [ ] - exp(x2 * 2.0939193)\n",
      "G04_0(X04): 7.09e-16 - [X] - (cos(x1) * sin(x0))\n",
      "G04_1(X04): 8.45e-14 - [X] - ((x2 * x2) * x2)\n",
      "G04_2(X04): 1.41e-14 - [X] - exp(x2)\n",
      "F05_0(G05): 1.68e-03 - [ ] - ((x1 + x0) - ((((x0 * cos(exp(exp(x2) * -0.39470685))) + x1) * x2) * -0.39470685))\n",
      "F05_0(X05): 1.32e-01 - [ ] - (x0 - (x3 * ((x1 * -1.5147587) * x3)))\n",
      "G05_0(X05): 0.00e+00 - [X] - x0\n",
      "G05_1(X05): 9.52e-15 - [X] - ((x1 * x3) * x3)\n",
      "G05_2(X05): 9.84e-11 - [X] - (log_abs(x3) + 0.6931462)\n",
      "F00_0(G00): 1.31e-14 - [X] - ((x0 + x2) + x1)\n",
      "F00_0(X00): 1.91e-14 - [X] - (((x0 + x1) * x0) + cos(x1))\n",
      "G00_0(X00): 1.33e-14 - [X] - (x0 * x0)\n",
      "G00_1(X00): 6.82e-16 - [X] - cos(x1)\n",
      "G00_2(X00): 2.39e-15 - [X] - (x0 * x1)\n",
      "F06_0(G06): 1.26e-14 - [X] - ((x1 + x0) + x2)\n",
      "F06_0(X06): 2.24e-14 - [X] - (((x0 * x0) + (x5 * x7)) + cos(x3))\n",
      "G06_0(X06): 1.20e-14 - [X] - (x0 * x0)\n",
      "G06_1(X06): 6.47e-16 - [X] - cos(x3)\n",
      "G06_2(X06): 2.55e-15 - [X] - (x5 * x7)\n"
     ]
    }
   ],
   "source": [
    "for d_var in models:\n",
    "    for i_var in models[d_var]:\n",
    "        for m, model in enumerate(models[d_var][i_var]):\n",
    "            best = model.get_best()\n",
    "            print(f\"{d_var}_{m}({i_var}): {best.loss:.2e} - [{(' ','X')[best.loss < disc_eps]}] - {best.equation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "540f5367292c701f747780e6da702d3852f1c7c25c6067d18f36ab6562a2dcf2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
