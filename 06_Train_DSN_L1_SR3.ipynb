{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c5e28e2",
   "metadata": {},
   "source": [
    "# 2022 Flatiron Machine Learning x Science Summer School\n",
    "\n",
    "## Step 6: Train DSN with $L_1$ regularization on latent features using GhostAdam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9ea49d",
   "metadata": {},
   "source": [
    "Based on [SR3](https://arxiv.org/abs/1807.05411)\n",
    "\n",
    "This is an approach to minimize prediction accuracy and regularization separately\n",
    "\n",
    "With the DSN, do we still have $a_1$ and $a_2$ combined?\n",
    "\n",
    "Let's explore this with a simple sweep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f30901e",
   "metadata": {},
   "source": [
    "Stuff is not working\n",
    "\n",
    "ghost_loss_backward:\n",
    "\n",
    "* get_param_differences_and_scales:\n",
    "\n",
    "    * get param_groups: dict per live/ghost\n",
    "    \n",
    "    * betas (Tuple[float, float], optional): coefficients used for computing running averages of gradient and its square default: (0.9, 0.999))\n",
    "    \n",
    "    * go through parameters\n",
    "    \n",
    "    * \n",
    "    \n",
    "    \n",
    "    \n",
    "Sanity check: set requires grad to 0 \n",
    "\n",
    "Do we make sure that unregularized parameters are not effected by our trick?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "We need to make sure that ghost parameters change with live parameters:\n",
    "    Set differences to 0 and set p.ghost to p.live?\n",
    "    \n",
    "necessary?\n",
    "all_p.append(p.live.sum() * 0.0 + p.ghost.sum() * 0.0)\n",
    "\n",
    "\n",
    "is hack slowing us down?\n",
    "\n",
    "ghost L1 activation:\n",
    "13:28<00:00, 12.36it/s, train_loss=2.09e-06, val_loss=1.20e-03\n",
    "\n",
    "vs. regular L1 loss:\n",
    "09:43<00:00, 17.15it/s, train_loss=3.34e-04, val_loss=1.83e-03\n",
    "\n",
    "vs. no ghost L1 activation:\n",
    "09:08<00:00, 18.23it/s, train_loss=1.90e-03, val_loss=1.92e-03\n",
    "\n",
    "vs. ghost L1 activation via 0 loss:\n",
    "13:12<00:00, 12.63it/s, train_loss=2.09e-06, val_loss=1.20e-03"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a5ca78",
   "metadata": {},
   "source": [
    "Error:\n",
    "\n",
    "python 3.7:\n",
    "reset_parameters()\n",
    "    self.model.parameters()\n",
    "        self.\n",
    "        model.: return GhostTuple\n",
    "        parameters(): GhostTuple: __getattr__ (name = parameters):\n",
    "            return GhostTuple(\n",
    "                live=getattr(self.live, name),\n",
    "                ghost=getattr(self.ghost, name),\n",
    "            )\n",
    "            __getitem__(index = 0):\n",
    "                 return GhostTuple(live=self.live[index], ghost=self.ghost[index])\n",
    "\n",
    "\n",
    "python 3.7:\n",
    "reset_parameters()\n",
    "    self.model.parameters()\n",
    "        self.\n",
    "        model.: return GhostTuple\n",
    "        parameters(): GhostTuple: __getattr__ (name = parameters):\n",
    "            return GhostTuple(\n",
    "                live=getattr(self.live, name),\n",
    "                ghost=getattr(self.ghost, name),\n",
    "            )\n",
    "            \n",
    "            just works\n",
    "            \n",
    "            \n",
    "https://docs.python.org/3/whatsnew/3.8.html\n",
    "Sped-up field lookups in collections.namedtuple(). They are now more than two times faster, making them the fastest form of instance variable lookup in Python. (Contributed by Raymond Hettinger, Pablo Galindo, and Joe Jevnik, Serhiy Storchaka in bpo-32492.)\n",
    "\n",
    "namedtuple isn't a class, as you note; it's a function. But it's a function that returns a class. Thus, you can use the result of the namedtuple call as a parent class.\n",
    "\n",
    "The problem with GhostTuples (GT) is that (in Python 3.7) GT1.live is processed as __getitem__(GT1, 0).\n",
    "\n",
    "So do we want __getitem__(GT1, 0) generally to return GT1.live or do we want GT2(live=GT1.live[0], ghost=GT1.ghost[1])?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "https://stackoverflow.com/questions/6738087/why-doesnt-python-have-a-hybrid-getattr-getitem-built-in\n",
    "I've given a fair bit of thought to this question, and I think the answer is very simple. When you create a container type, it's very important to distinguish between attributes and items. Any reasonably well-developed container type will have a number of attributes -- often though not always methods -- that enable it to manage its contents in graceful ways. So for example, a dict has items, values, keys, iterkeys and so on. These attributes are all accessed using . notation. Items, on the other hand, are accessed using [] notation. So there can be no collisions.\n",
    "\n",
    "What happens when you enable item access using . notation? Suddenly you have overlapping namespaces. How do you handle collisions now? If you subclass a dict and give it this functionality, either you can't use keys like items as a rule, or you have to create some kind of namespace hierarchy. The first option creates a rule that is onerous, hard to follow, and hard to enforce. The second option creates an annoying amount of complexity, without fully resolving the collision problem, since you still have to have an alternative interface to specify whether you want items the item or items the attribute.\n",
    "\n",
    "Now, for certain kinds of very primitive types, this is acceptable. That's probably why there's namedtuple in the standard library, for example. (But note that namedtuple is subject to these very problems, which is probably why it was implemented as a factory function (prevents inheritance) and uses weird, private method names like _asdict.)\n",
    "\n",
    "---\n",
    "\n",
    "Do we even want to create new GhostTuples all the time?\n",
    "\n",
    "\n",
    "py37: ghost_class\n",
    "01:36<00:00, 10.38it/s, train_loss=2.36e-04, val_loss=3.72e-03\n",
    "\n",
    "py38: ghost_class\n",
    "01:23<00:00, 11.92it/s, train_loss=2.36e-04, val_loss=3.72e-03\n",
    "\n",
    "py38: ghost_tuple\n",
    "01:25<00:00, 11.67it/s, train_loss=2.36e-04, val_loss=3.72e-03"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb977e3d",
   "metadata": {},
   "source": [
    "## 6.1 L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f72d1241",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "from srnet import SRNet, SRData\n",
    "import srnet_utils as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58e0538a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set wandb project\n",
    "wandb_project = \"61-l1-gc-study-F00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1595d1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparams = {\n",
    "#     \"arch\": {\n",
    "#         \"in_size\": train_data.in_data.shape[1],\n",
    "#         \"out_size\": train_data.target_data.shape[1],\n",
    "#         \"hid_num\": (2,0),\n",
    "#         \"hid_size\": 32, \n",
    "#         \"hid_type\": (\"DSN\", \"MLP\"),\n",
    "#         \"lat_size\": 16,\n",
    "#         },\n",
    "#     \"epochs\": 10000,\n",
    "#     \"runtime\": None,\n",
    "#     \"batch_size\": 64,\n",
    "#     \"lr\": 1e-4,\n",
    "#     \"wd\": 1e-4,\n",
    "#     \"l1\": 0.0,\n",
    "#     \"a1\": 0.0,\n",
    "#     \"a2\": 0.0,\n",
    "#     \"gc\": 0.0,\n",
    "#     \"shuffle\": True,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "117a8518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameter study\n",
    "hp_study = {\n",
    "    \"method\": \"grid\", # random, bayesian\n",
    "    #\"metric\": {\n",
    "    #    \"name\": \"val_loss\",\n",
    "    #    \"goal\": \"minimize\",\n",
    "    #},\n",
    "    \"parameters\": {\n",
    "        \"l1\": {\n",
    "            \"values\": [1e-4, 1e-3, 1e-2]\n",
    "        },\n",
    "        \"gc\": {\n",
    "            \"values\": [1e-5, 1e-4, 1e-3]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f73ef9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: ukt7pwp4\n",
      "Sweep URL: https://wandb.ai/fabxy/61-l1-gc-study-F00/sweeps/ukt7pwp4\n"
     ]
    }
   ],
   "source": [
    "# create sweep\n",
    "sweep_id = wandb.sweep(hp_study, project=wandb_project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b74b87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data from wandb\n",
    "file_ext = \".pkl\"\n",
    "\n",
    "api = wandb.Api()\n",
    "\n",
    "runs = api.runs(wandb_project)\n",
    "for run in runs:\n",
    "    for f in run.files():\n",
    "        if f.name[-len(file_ext):] == file_ext and not os.path.isfile(f.name):\n",
    "            print(f\"Downloading {os.path.basename(f.name)}.\")\n",
    "            run.file(f.name).download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e59b6b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdfc452d",
   "metadata": {},
   "source": [
    "## 6.2 DSN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58acdfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set wandb project\n",
    "wandb_project = \"62-a1-a2-gc-study-F00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7db3e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "# hyperparams = {\n",
    "#     \"arch\": {\n",
    "#         \"in_size\": train_data.in_data.shape[1],\n",
    "#         \"out_size\": train_data.target_data.shape[1],\n",
    "#         \"hid_num\": (2,0),\n",
    "#         \"hid_size\": 32, \n",
    "#         \"hid_type\": (\"DSN\", \"MLP\"),\n",
    "#         \"lat_size\": 16,\n",
    "#         },\n",
    "#     \"epochs\": 10000,\n",
    "#     \"runtime\": None,\n",
    "#     \"batch_size\": 64,\n",
    "#     \"lr\": 1e-4,\n",
    "#     \"wd\": 1e-4,\n",
    "#     \"l1\": 0.0,\n",
    "#     \"a1\": 0.0,\n",
    "#     \"a2\": 0.0,\n",
    "#     \"gc\": 0.0,\n",
    "#     \"shuffle\": True,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1129d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameter study\n",
    "hp_study = {\n",
    "    \"method\": \"grid\", # random, bayesian\n",
    "    #\"metric\": {\n",
    "    #    \"name\": \"val_loss\",\n",
    "    #    \"goal\": \"minimize\",\n",
    "    #},\n",
    "    \"parameters\": {\n",
    "        \"a1\": {\n",
    "            \"values\": [1e-5, 1e-3]\n",
    "        },\n",
    "        \"a2\": {\n",
    "            \"values\": [1e-5, 1e-3]\n",
    "        },\n",
    "        \"gc\": {\n",
    "            \"values\": [1e-5, 1e-4, 1e-3]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "141a740b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: h8ngmjg3\n",
      "Sweep URL: https://wandb.ai/fabxy/62-a1-a2-gc-study-F00/sweeps/h8ngmjg3\n"
     ]
    }
   ],
   "source": [
    "# create sweep\n",
    "sweep_id = wandb.sweep(hp_study, project=wandb_project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62daf607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data from wandb\n",
    "file_ext = \".pkl\"\n",
    "\n",
    "api = wandb.Api()\n",
    "\n",
    "runs = api.runs(wandb_project)\n",
    "for run in runs:\n",
    "    for f in run.files():\n",
    "        if f.name[-len(file_ext):] == file_ext and not os.path.isfile(f.name):\n",
    "            print(f\"Downloading {os.path.basename(f.name)}.\")\n",
    "            run.file(f.name).download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aece821",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
