{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c69c9c1",
   "metadata": {},
   "source": [
    "# 2022 Flatiron Machine Learning x Science Summer School\n",
    "\n",
    "## Step 5: Train DSN with $L_1$ regularization on latent features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390e36a0",
   "metadata": {},
   "source": [
    "### Step 5.1: Check $a_1$ and $a_2$ parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f72d1241",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "from srnet import SRNet, SRData\n",
    "import srnet_utils as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58e0538a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set wandb project\n",
    "wandb_project = \"51-a1-a2-study-F00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1595d1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "# hyperparams = {\n",
    "#     \"arch\": {\n",
    "#         \"in_size\": train_data.in_data.shape[1],\n",
    "#         \"out_size\": train_data.target_data.shape[1],\n",
    "#         \"hid_num\": (2,0),\n",
    "#         \"hid_size\": 32, \n",
    "#         \"hid_type\": (\"DSN\", \"MLP\"),\n",
    "#         \"lat_size\": 16,\n",
    "#         },\n",
    "#     \"epochs\": 10000,\n",
    "#     \"runtime\": None,\n",
    "#     \"batch_size\": 64,\n",
    "#     \"lr\": 1e-4,\n",
    "#     \"wd\": 1e-4,\n",
    "#     \"l1\": 0.0,\n",
    "#     \"a1\": 0.0,\n",
    "#     \"a2\": 0.0,\n",
    "#     \"shuffle\": True,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "117a8518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameter study\n",
    "hp_study = {\n",
    "    \"method\": \"grid\", # random, bayesian\n",
    "    #\"metric\": {\n",
    "    #    \"name\": \"val_loss\",\n",
    "    #    \"goal\": \"minimize\",\n",
    "    #},\n",
    "    \"parameters\": {\n",
    "        \"a1\": {\n",
    "            \"values\": [0.0, 1e-5, 1e-3, 1e-1]\n",
    "        },\n",
    "        \"a2\": {\n",
    "            \"values\": [0.0, 1e-5, 1e-3, 1e-1]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f73ef9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sweep\n",
    "sweep_id = wandb.sweep(hp_study, project=wandb_project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b74b87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data from wandb\n",
    "file_ext = \".pkl\"\n",
    "\n",
    "api = wandb.Api()\n",
    "\n",
    "runs = api.runs(wandb_project)\n",
    "for run in runs:\n",
    "    for f in run.files():\n",
    "        if f.name[-len(file_ext):] == file_ext and not os.path.isfile(f.name):\n",
    "            print(f\"Downloading {os.path.basename(f.name)}.\")\n",
    "            run.file(f.name).download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4294c8a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af09e89064644ca8ca234fb5ba21f4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot losses\n",
    "save_names = [\"F00_a1\"]\n",
    "excl_names = [\"gc\"]\n",
    "save_path = \"models\"\n",
    "models = ut.plot_losses(save_names, save_path=\"models\", excl_names=excl_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66162d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get states\n",
    "states = {}\n",
    "\n",
    "model_ext = \".pkl\"\n",
    "for model_name in models:\n",
    "    states[model_name + model_ext] = joblib.load(os.path.join(save_path, model_name + model_ext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4e82df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot losses\n",
    "save_temp = \"srnet_model_F00_a1_{a1:.0e}_a2_{a2:.0e}.pkl\"\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "for a2 in hp_study['parameters']['a2']['values']:\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    for a1 in hp_study['parameters']['a1']['values']:\n",
    "        save_name = save_temp.format(a1=a1, a2=a2)\n",
    "        train_loss.append(states[save_name]['total_train_loss'])\n",
    "        val_loss.append(states[save_name]['total_val_loss'])\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40a5c8f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db7da3fe8e6448b1b206433a8b413550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "a1s = [f\"{a1:.0e}\" for a1 in hp_study['parameters']['a1']['values']]\n",
    "a2s = [f\"{a2:.0e}\" for a2 in hp_study['parameters']['a2']['values']]\n",
    "\n",
    "psm = ax.pcolor(train_losses)\n",
    "\n",
    "fig.colorbar(psm, ax=ax)\n",
    "ax.set_xlabel(\"Parameter a1\")\n",
    "ax.set_ylabel(\"Parameter a2\")\n",
    "\n",
    "xticks = ax.get_xticks()[1::2]\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(a1s)\n",
    "\n",
    "yticks = ax.get_yticks()[1::2]\n",
    "ax.set_yticks(yticks)\n",
    "ax.set_yticklabels(a2s)\n",
    "\n",
    "ax.set_title(\"Training losses\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef24fe41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba5b5400c21f43118d4c66b2a3068569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "a1s = [f\"{a1:.0e}\" for a1 in hp_study['parameters']['a1']['values']]\n",
    "a2s = [f\"{a2:.0e}\" for a2 in hp_study['parameters']['a2']['values']]\n",
    "\n",
    "psm = ax.pcolor(val_losses)\n",
    "\n",
    "fig.colorbar(psm, ax=ax)\n",
    "ax.set_xlabel(\"Parameter a1\")\n",
    "ax.set_ylabel(\"Parameter a2\")\n",
    "\n",
    "xticks = ax.get_xticks()[1::2]\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(a1s)\n",
    "\n",
    "yticks = ax.get_yticks()[1::2]\n",
    "ax.set_yticks(yticks)\n",
    "ax.set_yticklabels(a2s)\n",
    "\n",
    "ax.set_title(\"Validation losses\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fcc1db",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "* Values of `1e-01` for the DSN parameters $a_1$ and $a_2$ lead to significant jumps in the validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f5b78ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data_path = \"data_1k\"\n",
    "\n",
    "in_var = \"X00\"\n",
    "lat_var = \"G00\"\n",
    "target_var = \"F00\"\n",
    "\n",
    "mask_ext = \".mask\"\n",
    "masks = joblib.load(os.path.join(data_path, in_var + mask_ext))     # TODO: create mask if file does not exist\n",
    "\n",
    "train_data = SRData(data_path, in_var, lat_var, target_var, masks[\"train\"])\n",
    "val_data = SRData(data_path, in_var, lat_var, target_var, masks[\"val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf5019e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "srnet_model_F00_a1_0e+00_a2_1e-05\n",
      "[0.6663477, 0.22754952, 0.13303775, 0.08057226, 0.07956417, 0.008945408, 3.1225023e-17, 1.3877788e-17, 1.3877788e-17, 1.3877788e-17, 1.3877788e-17, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0, 7, 15, 9, 1, 13, 2, 4, 8, 10, 14, 3, 5, 6, 11, 12]\n",
      "[[-1.1827385  -1.1604899 ]\n",
      " [-0.5680361  -0.7426323 ]\n",
      " [ 1.1502272  -0.39936063]\n",
      " [ 0.7791239   0.77259094]\n",
      " [-0.5597268   0.48970914]\n",
      " [ 1.0314969  -0.8139722 ]]\n",
      "\n",
      "srnet_model_F00_a1_0e+00_a2_1e-03\n",
      "[0.6579603, 0.16474427, 0.0218615, 0.017693432, 0.004262521, 1.0098834e-06, 3.1225023e-17, 1.3877788e-17, 3.469447e-18, 8.6736174e-19, 2.1684043e-19, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0, 1, 15, 9, 13, 7, 12, 8, 4, 2, 14, 3, 5, 6, 10, 11]\n",
      "[[-6.9626713e-01 -5.4629576e-01]\n",
      " [-4.4165763e-01 -3.9943978e-01]\n",
      " [ 1.0977784e-01  3.2188484e-06]\n",
      " [ 4.6725744e-01  5.8694594e-02]\n",
      " [-4.0847880e-01  1.4354388e-01]\n",
      " [ 5.2012444e-01 -1.4175722e-01]]\n",
      "\n",
      "srnet_model_F00_a1_1e-05_a2_1e-03\n",
      "[0.7007249, 0.16599274, 0.022339601, 0.010651008, 0.0034628494, 1.5755894e-08, 3.1225023e-17, 1.3877788e-17, 8.6736174e-19, 8.6736174e-19, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0, 1, 9, 15, 13, 7, 12, 8, 2, 14, 3, 4, 5, 6, 10, 11]\n",
      "[[-6.9769609e-01 -5.4090250e-01]\n",
      " [-4.3820301e-01 -3.8749045e-01]\n",
      " [ 5.5093076e-02  4.8218321e-06]\n",
      " [ 4.6923199e-01  8.0085538e-02]\n",
      " [-4.0097216e-01  1.4224520e-01]\n",
      " [ 4.9253431e-01 -4.2777900e-02]]\n",
      "\n",
      "srnet_model_F00_a1_1e-03_a2_1e-03\n",
      "[0.54778475, 0.121214814, 0.06913294, 5.551115e-17, 1.3877788e-17, 1.3877788e-17, 8.6736174e-19, 8.6736174e-19, 8.6736174e-19, 1.9058241e-21, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0, 1, 15, 9, 7, 10, 2, 4, 11, 5, 3, 6, 8, 12, 13, 14]\n",
      "[[-3.8896823e-01 -2.9392710e-01]\n",
      " [-2.7494454e-01 -1.4383869e-01]\n",
      " [ 2.9747337e-01 -1.1428459e-05]]\n",
      "\n",
      "srnet_model_F00_a1_1e-01_a2_1e-03\n",
      "[0.8392321, 1.7712815e-15, 2.220446e-16, 2.220446e-16, 1.3877788e-17, 3.469447e-18, 2.1684043e-19, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[8, 9, 7, 14, 15, 1, 4, 0, 2, 3, 5, 6, 10, 11, 12, 13]\n",
      "[[-0.03729606 -0.02195824]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# overview latent feature variance and alpha matrix\n",
    "model_path = \"models\"\n",
    "model_ext = \".pkl\"\n",
    "\n",
    "models = [\n",
    "    \"srnet_model_F00_a1_0e+00_a2_1e-05\",\n",
    "    \"srnet_model_F00_a1_0e+00_a2_1e-03\",\n",
    "    \"srnet_model_F00_a1_1e-05_a2_1e-03\",\n",
    "    \"srnet_model_F00_a1_1e-03_a2_1e-03\",\n",
    "    \"srnet_model_F00_a1_1e-01_a2_1e-03\",\n",
    "]\n",
    "\n",
    "alpha_eps = 1e-4\n",
    "\n",
    "for model_name in models:\n",
    "    print(model_name)\n",
    "    model = ut.load_model(model_name + model_ext, model_path, SRNet)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        preds, acts = model(train_data.in_data, get_lat=True)\n",
    "        \n",
    "    ut.get_node_order(acts, show=True)\n",
    "    \n",
    "    alpha = model.layers1.alpha.detach().cpu().numpy()\n",
    "    print(alpha[np.abs(alpha).sum(axis=1) > alpha_eps])\n",
    "    \n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d019d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "srnet_model_F00_a1_1e-05_a2_0e+00\n",
      "[0.6776226, 0.22553541, 0.13323744, 0.07859352, 0.06688577, 0.010254435, 1.3877788e-17, 1.3877788e-17, 1.3877788e-17, 1.3877788e-17, 3.469447e-18, 3.469447e-18, 0.0, 0.0, 0.0, 0.0]\n",
      "[0, 7, 15, 1, 9, 13, 4, 5, 8, 10, 2, 14, 3, 6, 11, 12]\n",
      "[[-1.1732184  -1.1535953 ]\n",
      " [-0.5607364  -0.71192485]\n",
      " [ 1.135986   -0.36854565]\n",
      " [ 0.7656966   0.7304388 ]\n",
      " [-0.5511235   0.47454327]\n",
      " [ 1.0226839  -0.8039612 ]]\n",
      "\n",
      "srnet_model_F00_a1_1e-03_a2_0e+00\n",
      "[0.6201504, 0.1632466, 0.07770574, 5.3266916e-16, 5.551115e-17, 5.551115e-17, 5.551115e-17, 1.3877788e-17, 1.3877788e-17, 8.6736174e-19, 2.1684043e-19, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0, 15, 1, 9, 8, 10, 13, 4, 11, 5, 14, 2, 3, 6, 7, 12]\n",
      "[[-0.52056277 -0.42505166]\n",
      " [-0.289202   -0.15479507]\n",
      " [ 0.44180116 -0.09080692]]\n",
      "\n",
      "srnet_model_F00_a1_1e-05_a2_1e-05\n",
      "[0.6577685, 0.19030869, 0.12078818, 0.080249384, 0.07855751, 0.008998795, 5.551115e-17, 1.3877788e-17, 1.3877788e-17, 1.3877788e-17, 3.469447e-18, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0, 7, 15, 9, 1, 13, 5, 4, 10, 11, 14, 2, 3, 6, 8, 12]\n",
      "[[-1.1700627  -1.1372367 ]\n",
      " [-0.5641579  -0.7171804 ]\n",
      " [ 1.117989   -0.33887896]\n",
      " [ 0.769312    0.7489827 ]\n",
      " [-0.55366415  0.47240412]\n",
      " [ 1.0084268  -0.77895594]]\n",
      "\n",
      "srnet_model_F00_a1_1e-05_a2_1e-03\n",
      "[0.7007249, 0.16599274, 0.022339601, 0.010651008, 0.0034628494, 1.5755894e-08, 3.1225023e-17, 1.3877788e-17, 8.6736174e-19, 8.6736174e-19, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0, 1, 9, 15, 13, 7, 12, 8, 2, 14, 3, 4, 5, 6, 10, 11]\n",
      "[[-6.9769609e-01 -5.4090250e-01]\n",
      " [-4.3820301e-01 -3.8749045e-01]\n",
      " [ 5.5093076e-02  4.8218321e-06]\n",
      " [ 4.6923199e-01  8.0085538e-02]\n",
      " [-4.0097216e-01  1.4224520e-01]\n",
      " [ 4.9253431e-01 -4.2777900e-02]]\n",
      "\n",
      "srnet_model_F00_a1_1e-05_a2_1e-01\n",
      "[0.7640827, 2.220446e-16, 2.220446e-16, 3.469447e-18, 4.87891e-19, 7.4446255e-24, 1.92593e-34, 3e-45, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[9, 0, 1, 14, 13, 12, 4, 11, 2, 3, 5, 6, 7, 8, 10, 15]\n",
      "[[0.03664039 0.01987458]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# overview latent feature variance and alpha matrix\n",
    "model_path = \"models\"\n",
    "model_ext = \".pkl\"\n",
    "\n",
    "models = [    \n",
    "    \"srnet_model_F00_a1_1e-05_a2_0e+00\",\n",
    "    \"srnet_model_F00_a1_1e-03_a2_0e+00\",\n",
    "    \"srnet_model_F00_a1_1e-05_a2_1e-05\",\n",
    "    \"srnet_model_F00_a1_1e-05_a2_1e-03\",\n",
    "    \"srnet_model_F00_a1_1e-05_a2_1e-01\",\n",
    "]\n",
    "\n",
    "alpha_eps = 1e-4\n",
    "\n",
    "for model_name in models:\n",
    "    print(model_name)\n",
    "    model = ut.load_model(model_name + model_ext, model_path, SRNet)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        preds, acts = model(train_data.in_data, get_lat=True)\n",
    "        \n",
    "    ut.get_node_order(acts, show=True)\n",
    "    \n",
    "    alpha = model.layers1.alpha.detach().cpu().numpy()\n",
    "    print(alpha[np.abs(alpha).sum(axis=1) > alpha_eps])\n",
    "    \n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65118ad",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "* Interestingly, sparsity is already enforced for $a_2 > 0$ while $a_1 = 0$ (although it is enforced more strongly by $a_1$):\n",
    "\n",
    "    * $a_1 = 1\\text{e-}5$: `0.6776226, 0.22553541, 0.13323744, 0.07859352, 0.06688577, 0.010254435`\n",
    "    * $a_2 = 1\\text{e-}5$: `0.6663477, 0.22754952, 0.13303775, 0.08057226, 0.07956417, 0.008945408`\n",
    "    * $a_1 = 1\\text{e-}3$: `0.6201504, 0.1632466, 0.07770574, 5.3266916e-16, 5.551115e-17, 5.551115e-17`\n",
    "    * $a_2 = 1\\text{e-}3$: `0.6579603, 0.16474427, 0.0218615, 0.017693432, 0.004262521, 1.0098834e-06`\n",
    "\n",
    "* Generally, $a_1$ and $a_2$ seem to have a surprisingly similar effect\n",
    "\n",
    "* However, increasing $a_2$ does not seem to promote low input feature dependencies\n",
    "\n",
    "Was the original loss function definition (sparsity over columns of `alpha`) better than the new one (sparsity over rows of `alpha`) better after all?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ae00586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "srnet_model_F00_a1_1e-05_a2_1e-03\n",
      "[0.7007249, 0.16599274, 0.022339601, 0.010651008, 0.0034628494, 1.5755894e-08, 3.1225023e-17, 1.3877788e-17, 8.6736174e-19, 8.6736174e-19, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0, 1, 9, 15, 13, 7, 12, 8, 2, 14, 3, 4, 5, 6, 10, 11]\n",
      "[[-6.9769609e-01 -5.4090250e-01]\n",
      " [-4.3820301e-01 -3.8749045e-01]\n",
      " [ 5.5093076e-02  4.8218321e-06]\n",
      " [ 4.6923199e-01  8.0085538e-02]\n",
      " [-4.0097216e-01  1.4224520e-01]\n",
      " [ 4.9253431e-01 -4.2777900e-02]]\n",
      "\n",
      "extra/srnet_model_F00_a1_1e-05_a2_1e-03_dim0\n",
      "[0.8296081, 0.101969145, 0.016981106, 0.003976508, 5.551115e-17, 5.551115e-17, 1.3877788e-17, 1.3877788e-17, 1.3877788e-17, 3.469447e-18, 5.421011e-20, 5.421011e-20, 2.1175824e-22, 0.0, 0.0, 0.0]\n",
      "[0, 1, 15, 9, 7, 13, 8, 10, 12, 4, 2, 5, 14, 3, 6, 11]\n",
      "[[-6.1068958e-01 -5.8874309e-01]\n",
      " [-3.2437617e-01 -2.6313716e-01]\n",
      " [ 2.8077862e-01 -5.6885201e-06]\n",
      " [ 3.3674622e-01 -3.9087702e-03]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# overview latent feature variance and alpha matrix\n",
    "model_path = \"models\"\n",
    "model_ext = \".pkl\"\n",
    "\n",
    "models = [\n",
    "    \"srnet_model_F00_a1_1e-05_a2_1e-03\",\n",
    "    \"extra/srnet_model_F00_a1_1e-05_a2_1e-03_dim0\",\n",
    "    # \"extra/srnet_model_F00_a1_1e-03_a2_1e-03_newreg2\",\n",
    "]\n",
    "\n",
    "alpha_eps = 1e-4\n",
    "\n",
    "for model_name in models:\n",
    "    print(model_name)\n",
    "    model = ut.load_model(model_name + model_ext, model_path, SRNet)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        preds, acts = model(train_data.in_data, get_lat=True)\n",
    "        \n",
    "    ut.get_node_order(acts, show=True)\n",
    "    \n",
    "    alpha = model.layers1.alpha.detach().cpu().numpy()\n",
    "    print(alpha[np.abs(alpha).sum(axis=1) > alpha_eps])\n",
    "    \n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6d1706",
   "metadata": {},
   "source": [
    "Not really. There is more sparsity, but the high-variance latent features still both depend on both input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1c2544e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.54778475, 0.121214814, 0.06913294, 5.551115e-17, 1.3877788e-17, 1.3877788e-17, 8.6736174e-19, 8.6736174e-19, 8.6736174e-19, 1.9058241e-21, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0, 1, 15, 9, 7, 10, 2, 4, 11, 5, 3, 6, 8, 12, 13, 14]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"srnet_model_F00_a1_1e-03_a2_1e-03\"\n",
    "\n",
    "model = ut.load_model(model_name + model_ext, model_path, SRNet)\n",
    "\n",
    "with torch.no_grad():\n",
    "    preds, acts = model(train_data.in_data, get_lat=True)\n",
    "    \n",
    "all_nodes = ut.get_node_order(acts, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bf3da1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = all_nodes[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8941821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select plotting data\n",
    "x_data = train_data.in_data[:,0]\n",
    "y_data = train_data.in_data[:,1]\n",
    "z_data = [\n",
    "    (\"target\", train_data.target_data),\n",
    "    #(\"x**2\", x_data**2), \n",
    "    #(\"cos(y)\", np.cos(y_data)), \n",
    "    #(\"x*y\", x_data * y_data),\n",
    "]\n",
    "plot_size = train_data.target_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24d2295a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5c76c00e9a24bf591d880528fc53be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ut.plot_acts(x_data, y_data, z_data, acts=acts, nodes=nodes, model=model, bias=True, nonzero=False, agg=False, plot_size=plot_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a6fefac",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_data = [\n",
    "    (\"x**2\", x_data**2), \n",
    "    (\"cos(y)\", np.cos(y_data)), \n",
    "    (\"x*y\", x_data * y_data),\n",
    "    (\"x\", x_data),\n",
    "    (\"y\", y_data),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98c12536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Node 0\n",
      "corr(n0, x**2): -0.6975\n",
      "corr(n0, cos(y)): -0.2926\n",
      "corr(n0, x*y): -0.7199\n",
      "corr(n0, x): -0.2426\n",
      "corr(n0, y): -0.1217\n",
      "\n",
      "Node 1\n",
      "corr(n1, x**2): -0.8321\n",
      "corr(n1, cos(y)): 0.0010\n",
      "corr(n1, x*y): -0.4605\n",
      "corr(n1, x): 0.0079\n",
      "corr(n1, y): 0.1556\n",
      "\n",
      "Node 15\n",
      "corr(n15, x**2): 0.7999\n",
      "corr(n15, cos(y)): -0.0074\n",
      "corr(n15, x*y): 0.1791\n",
      "corr(n15, x): 0.7783\n",
      "corr(n15, y): 0.0390\n"
     ]
    }
   ],
   "source": [
    "ut.node_correlations(acts, nodes, corr_data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "002db46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8296081, 0.101969145, 0.016981106, 0.003976508, 5.551115e-17, 5.551115e-17, 1.3877788e-17, 1.3877788e-17, 1.3877788e-17, 3.469447e-18, 5.421011e-20, 5.421011e-20, 2.1175824e-22, 0.0, 0.0, 0.0]\n",
      "[0, 1, 15, 9, 7, 13, 8, 10, 12, 4, 2, 5, 14, 3, 6, 11]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"extra/srnet_model_F00_a1_1e-05_a2_1e-03_dim0\"\n",
    "\n",
    "model = ut.load_model(model_name + model_ext, model_path, SRNet)\n",
    "\n",
    "with torch.no_grad():\n",
    "    preds, acts = model(train_data.in_data, get_lat=True)\n",
    "    \n",
    "all_nodes = ut.get_node_order(acts, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c660bac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = all_nodes[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cea3dd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select plotting data\n",
    "x_data = train_data.in_data[:,0]\n",
    "y_data = train_data.in_data[:,1]\n",
    "z_data = [\n",
    "    (\"target\", train_data.target_data),\n",
    "    #(\"x**2\", x_data**2), \n",
    "    #(\"cos(y)\", np.cos(y_data)), \n",
    "    #(\"x*y\", x_data * y_data),\n",
    "]\n",
    "plot_size = train_data.target_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01eeeac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2741506e6684998afed679a2480715c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ut.plot_acts(x_data, y_data, z_data, acts=acts, nodes=nodes, model=model, bias=True, nonzero=False, agg=False, plot_size=plot_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c77907c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_data = [\n",
    "    (\"x**2\", x_data**2), \n",
    "    (\"cos(y)\", np.cos(y_data)), \n",
    "    (\"x*y\", x_data * y_data),\n",
    "    (\"x\", x_data),\n",
    "    (\"y\", y_data),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc91e86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Node 0\n",
      "corr(n0, x**2): -0.7488\n",
      "corr(n0, cos(y)): -0.2480\n",
      "corr(n0, x*y): -0.6872\n",
      "corr(n0, x): -0.3455\n",
      "corr(n0, y): -0.0726\n",
      "\n",
      "Node 1\n",
      "corr(n1, x**2): -0.7921\n",
      "corr(n1, cos(y)): -0.0524\n",
      "corr(n1, x*y): -0.5029\n",
      "corr(n1, x): 0.0490\n",
      "corr(n1, y): 0.0655\n",
      "\n",
      "Node 15\n",
      "corr(n15, x**2): 0.8090\n",
      "corr(n15, cos(y)): 0.0037\n",
      "corr(n15, x*y): 0.1731\n",
      "corr(n15, x): 0.7224\n",
      "corr(n15, y): 0.0314\n",
      "\n",
      "Node 9\n",
      "corr(n9, x**2): -0.7803\n",
      "corr(n9, cos(y)): 0.0008\n",
      "corr(n9, x*y): -0.1040\n",
      "corr(n9, x): 0.2995\n",
      "corr(n9, y): -0.0266\n"
     ]
    }
   ],
   "source": [
    "ut.node_correlations(acts, nodes, corr_data);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33f476c",
   "metadata": {},
   "source": [
    "### Step 5.2: Check $a_1$ and $a_2$ parameters for `F06`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6496125b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set wandb project\n",
    "wandb_project = \"52-a1-a2-study-F06\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b116c6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "# hyperparams = {\n",
    "#     \"arch\": {\n",
    "#         \"in_size\": train_data.in_data.shape[1],\n",
    "#         \"out_size\": train_data.target_data.shape[1],\n",
    "#         \"hid_num\": (2,0),\n",
    "#         \"hid_size\": 32, \n",
    "#         \"hid_type\": (\"DSN\", \"MLP\"),\n",
    "#         \"lat_size\": 16,\n",
    "#         },\n",
    "#     \"epochs\": 10000,\n",
    "#     \"runtime\": None,\n",
    "#     \"batch_size\": 64,\n",
    "#     \"lr\": 1e-4,\n",
    "#     \"wd\": 1e-4,\n",
    "#     \"l1\": 0.0,\n",
    "#     \"a1\": 0.0,\n",
    "#     \"a2\": 0.0,\n",
    "#     \"gc\": 0.0,\n",
    "#     \"shuffle\": True,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "879a31d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameter study\n",
    "hp_study = {\n",
    "    \"method\": \"grid\", # random, bayesian\n",
    "    #\"metric\": {\n",
    "    #    \"name\": \"val_loss\",\n",
    "    #    \"goal\": \"minimize\",\n",
    "    #},\n",
    "    \"parameters\": {\n",
    "        \"a1\": {\n",
    "            \"values\": [0.0, 1e-5, 1e-3, 1e-1]\n",
    "        },\n",
    "        \"a2\": {\n",
    "            \"values\": [0.0, 1e-5, 1e-3, 1e-1]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b91596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sweep\n",
    "sweep_id = wandb.sweep(hp_study, project=wandb_project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ff5ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data from wandb\n",
    "file_ext = \".pkl\"\n",
    "\n",
    "api = wandb.Api()\n",
    "\n",
    "runs = api.runs(wandb_project)\n",
    "for run in runs:\n",
    "    for f in run.files():\n",
    "        if f.name[-len(file_ext):] == file_ext and not os.path.isfile(f.name):\n",
    "            print(f\"Downloading {os.path.basename(f.name)}.\")\n",
    "            run.file(f.name).download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c315451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c2e313644264f239e8384a2b51b76e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot losses\n",
    "save_names = [\"F06_a1\"]\n",
    "excl_names = [\"gc\"]\n",
    "save_path = \"models\"\n",
    "models = ut.plot_losses(save_names, save_path=\"models\", excl_names=excl_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a1068f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get states\n",
    "states = {}\n",
    "\n",
    "model_ext = \".pkl\"\n",
    "for model_name in models:\n",
    "    states[model_name + model_ext] = joblib.load(os.path.join(save_path, model_name + model_ext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d3cd769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot losses\n",
    "save_temp = \"srnet_model_F06_a1_{a1:.0e}_a2_{a2:.0e}.pkl\"\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "for a2 in hp_study['parameters']['a2']['values']:\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    for a1 in hp_study['parameters']['a1']['values']:\n",
    "        save_name = save_temp.format(a1=a1, a2=a2)\n",
    "        try:\n",
    "            train_loss.append(states[save_name]['total_train_loss'])\n",
    "            val_loss.append(states[save_name]['total_val_loss'])\n",
    "        except:\n",
    "            train_loss.append(-1)\n",
    "            val_loss.append(-1)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "# correct missing losses\n",
    "train_losses = np.array(train_losses)\n",
    "val_losses = np.array(val_losses)\n",
    "train_losses[train_losses < 0] = np.max(train_losses)\n",
    "val_losses[val_losses < 0] = np.max(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "922ca02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4bf4537d79449228c0a3cdb0d675c8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "a1s = [f\"{a1:.0e}\" for a1 in hp_study['parameters']['a1']['values']]\n",
    "a2s = [f\"{a2:.0e}\" for a2 in hp_study['parameters']['a2']['values']]\n",
    "\n",
    "psm = ax.pcolor(train_losses)\n",
    "\n",
    "fig.colorbar(psm, ax=ax)\n",
    "ax.set_xlabel(\"Parameter a1\")\n",
    "ax.set_ylabel(\"Parameter a2\")\n",
    "\n",
    "xticks = ax.get_xticks()[1::2]\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(a1s)\n",
    "\n",
    "yticks = ax.get_yticks()[1::2]\n",
    "ax.set_yticks(yticks)\n",
    "ax.set_yticklabels(a2s)\n",
    "\n",
    "ax.set_title(\"Training losses\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d4f224bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa010d2414644103ac61f77cce3f9e97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "a1s = [f\"{a1:.0e}\" for a1 in hp_study['parameters']['a1']['values']]\n",
    "a2s = [f\"{a2:.0e}\" for a2 in hp_study['parameters']['a2']['values']]\n",
    "\n",
    "psm = ax.pcolor(val_losses)\n",
    "\n",
    "fig.colorbar(psm, ax=ax)\n",
    "ax.set_xlabel(\"Parameter a1\")\n",
    "ax.set_ylabel(\"Parameter a2\")\n",
    "\n",
    "xticks = ax.get_xticks()[1::2]\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(a1s)\n",
    "\n",
    "yticks = ax.get_yticks()[1::2]\n",
    "ax.set_yticks(yticks)\n",
    "ax.set_yticklabels(a2s)\n",
    "\n",
    "ax.set_title(\"Validation losses\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23dd132",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "* In contrast to `F00`, the maximum value for $a_2$ leads to the best validation error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "890c7be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data_path = \"data_1k\"\n",
    "\n",
    "in_var = \"X06\"\n",
    "lat_var = \"G06\"\n",
    "target_var = \"F06\"\n",
    "\n",
    "mask_ext = \".mask\"\n",
    "masks = joblib.load(os.path.join(data_path, in_var + mask_ext))     # TODO: create mask if file does not exist\n",
    "\n",
    "train_data = SRData(data_path, in_var, lat_var, target_var, masks[\"train\"])\n",
    "val_data = SRData(data_path, in_var, lat_var, target_var, masks[\"val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "54843122",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "srnet_model_F06_a1_0e+00_a2_1e-01\n",
      "[0.2793835, 0.21531022, 0.07293549, 0.03322749, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[6, 13, 7, 3, 0, 1, 2, 4, 5, 8, 9, 10, 11, 12, 14, 15]\n",
      "[[0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      "srnet_model_F06_a1_1e-05_a2_1e-01\n",
      "[0.231994, 0.1972766, 0.07445352, 0.05141343, 1.3877788e-17, 1.1754944e-38, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[6, 13, 7, 3, 5, 2, 0, 1, 4, 8, 9, 10, 11, 12, 14, 15]\n",
      "[[0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      "srnet_model_F06_a1_1e-03_a2_1e-01\n",
      "[0.20505397, 0.20377514, 0.074096635, 0.071012214, 5.551115e-17, 1.3877788e-17, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[6, 13, 3, 7, 9, 5, 0, 1, 2, 4, 8, 10, 11, 12, 14, 15]\n",
      "[[0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      "srnet_model_F06_a1_1e-01_a2_1e-01\n",
      "[0.46574995, 0.13628185, 0.052221406, 2.2394784e-16, 1.3877788e-17, 8.6736174e-19, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[9, 2, 7, 5, 13, 12, 0, 1, 3, 4, 6, 8, 10, 11, 14, 15]\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# overview latent feature variance and alpha matrix\n",
    "model_path = \"models\"\n",
    "model_ext = \".pkl\"\n",
    "\n",
    "models = [\n",
    "    \"srnet_model_F06_a1_0e+00_a2_1e-01\",\n",
    "    \"srnet_model_F06_a1_1e-05_a2_1e-01\",\n",
    "    \"srnet_model_F06_a1_1e-03_a2_1e-01\",\n",
    "    \"srnet_model_F06_a1_1e-01_a2_1e-01\",\n",
    "]\n",
    "\n",
    "alpha_eps = 1e-2\n",
    "alpha_bin = True\n",
    "\n",
    "for model_name in models:\n",
    "    print(model_name)\n",
    "    model = ut.load_model(model_name + model_ext, model_path, SRNet)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        preds, acts = model(train_data.in_data, get_lat=True)\n",
    "        \n",
    "    ut.get_node_order(acts, show=True)\n",
    "    \n",
    "    if alpha_eps:\n",
    "        alpha = model.layers1.alpha.detach().cpu().numpy()[all_nodes]\n",
    "        \n",
    "        if alpha_bin:\n",
    "            alpha[np.abs(alpha) < alpha_eps] = 0\n",
    "            alpha[np.abs(alpha) > alpha_eps] = 1\n",
    "        \n",
    "        print(alpha[np.abs(alpha).sum(axis=1) > alpha_eps])\n",
    "    \n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "37afda4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "srnet_model_F06_a1_1e-03_a2_0e+00\n",
      "[0.21198046, 0.1942896, 0.17368312, 0.10920197, 0.06532583, 0.04275698, 0.030567221, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[2, 3, 7, 13, 6, 9, 5, 0, 1, 4, 8, 10, 11, 12, 14, 15]\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 1. 0. 1. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      "srnet_model_F06_a1_1e-03_a2_1e-05\n",
      "[0.27475622, 0.2353662, 0.17284352, 0.105235115, 0.063140385, 0.03077288, 0.001204764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[3, 2, 7, 13, 6, 5, 9, 0, 1, 4, 8, 10, 11, 12, 14, 15]\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 1. 0. 1. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      "srnet_model_F06_a1_1e-03_a2_1e-03\n",
      "[0.3584506, 0.16501725, 0.1549626, 0.13812137, 0.04587842, 0.002812615, 2.537086e-06, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[3, 7, 13, 2, 6, 5, 9, 0, 1, 4, 8, 10, 11, 12, 14, 15]\n",
      "[[0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 1. 0. 1. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      "srnet_model_F06_a1_1e-03_a2_1e-01\n",
      "[0.20505397, 0.20377514, 0.074096635, 0.071012214, 5.551115e-17, 1.3877788e-17, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[6, 13, 3, 7, 9, 5, 0, 1, 2, 4, 8, 10, 11, 12, 14, 15]\n",
      "[[0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# overview latent feature variance and alpha matrix\n",
    "model_path = \"models\"\n",
    "model_ext = \".pkl\"\n",
    "\n",
    "models = [\n",
    "    \"srnet_model_F06_a1_1e-03_a2_0e+00\",\n",
    "    \"srnet_model_F06_a1_1e-03_a2_1e-05\",\n",
    "    \"srnet_model_F06_a1_1e-03_a2_1e-03\",\n",
    "    \"srnet_model_F06_a1_1e-03_a2_1e-01\",\n",
    "]\n",
    "\n",
    "alpha_eps = 1e-2\n",
    "alpha_bin = True\n",
    "\n",
    "for model_name in models:\n",
    "    print(model_name)\n",
    "    model = ut.load_model(model_name + model_ext, model_path, SRNet)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        preds, acts = model(train_data.in_data, get_lat=True)\n",
    "        \n",
    "    ut.get_node_order(acts, show=True)\n",
    "    \n",
    "    if alpha_eps:\n",
    "        alpha = model.layers1.alpha.detach().cpu().numpy()[all_nodes]\n",
    "        \n",
    "        if alpha_bin:\n",
    "            alpha[np.abs(alpha) < alpha_eps] = 0\n",
    "            alpha[np.abs(alpha) > alpha_eps] = 1\n",
    "        \n",
    "        print(alpha[np.abs(alpha).sum(axis=1) > alpha_eps])\n",
    "    \n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c162d7a9",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "* For $a_2$ being `1e-01` and $a_1$ < `1e-01`, $x_0^2$ is split into two latent features\n",
    "\n",
    "* For $a_1$ and $a_2$ being `1e-01` the correct split is achieved!\n",
    "\n",
    "* For $a_2$ < `1e-01`, the latent features are not split correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "755a260a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.46574995, 0.13628185, 0.052221406, 2.2394784e-16, 1.3877788e-17, 8.6736174e-19, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[9, 2, 7, 5, 13, 12, 0, 1, 3, 4, 6, 8, 10, 11, 14, 15]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"srnet_model_F06_a1_1e-01_a2_1e-01\"\n",
    "\n",
    "model = ut.load_model(model_name + model_ext, model_path, SRNet)\n",
    "\n",
    "with torch.no_grad():\n",
    "    preds, acts = model(train_data.in_data, get_lat=True)\n",
    "    \n",
    "all_nodes = ut.get_node_order(acts, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4b47e6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = all_nodes[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "96e14e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select data\n",
    "x0_data = train_data.in_data[:,0]\n",
    "x3_data = train_data.in_data[:,3]\n",
    "x5_data = train_data.in_data[:,5]\n",
    "x7_data = train_data.in_data[:,7]\n",
    "\n",
    "corr_data = [\n",
    "    (\"x0**2\", x0_data**2), \n",
    "    (\"cos(x3)\", np.cos(x3_data)), \n",
    "    (\"x5*x7\", x5_data * x7_data),\n",
    "    # (\"x0\", x0_data),\n",
    "    # (\"x3\", x3_data),\n",
    "    # (\"x5\", x5_data),\n",
    "    # (\"x7\", x7_data),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "43a31668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Node 9\n",
      "corr(n9, x0**2): 0.9999\n",
      "corr(n9, cos(x3)): -0.0003\n",
      "corr(n9, x5*x7): 0.0462\n",
      "\n",
      "Node 2\n",
      "corr(n2, x0**2): -0.0468\n",
      "corr(n2, cos(x3)): 0.0082\n",
      "corr(n2, x5*x7): -0.9998\n",
      "\n",
      "Node 7\n",
      "corr(n7, x0**2): -0.0001\n",
      "corr(n7, cos(x3)): -0.9997\n",
      "corr(n7, x5*x7): 0.0091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.9999155972804934, -0.000313703317180114, 0.04621954791806068],\n",
       " [-0.04683840318915195, 0.008199553788688748, -0.999789552463771],\n",
       " [-0.0001496457743340833, -0.9997031211410643, 0.00907727638484032]]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ut.node_correlations(acts, nodes, corr_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa30900f",
   "metadata": {},
   "source": [
    "Great result! \n",
    "\n",
    "Apparently, using GhostAdam is not required for this problem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
