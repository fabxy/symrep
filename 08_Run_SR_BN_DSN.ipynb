{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2022 Flatiron Machine Learning x Science Summer School\n",
    "\n",
    "## Step 8: Run symbolic regression on bottleneck DSN predictions\n",
    "\n",
    "In this step, we perform symbolic regression on the latent feature and target predictions of bottleneck DSNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "from pysr import PySRRegressor\n",
    "import sympy\n",
    "from scipy import optimize\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8.1: Load data\n",
    "\n",
    "We load the input data as well as the latent feature and target prediction data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data_1k\"\n",
    "data_ext = \".gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded F00 data.\n",
      "Loaded F00_p1 data.\n",
      "Loaded F01 data.\n",
      "Loaded F02 data.\n",
      "Loaded F03 data.\n",
      "Loaded F04 data.\n",
      "Loaded F05 data.\n",
      "Loaded F06 data.\n",
      "Loaded F07 data.\n",
      "Loaded F07_p1 data.\n",
      "Loaded F08 data.\n",
      "Loaded F09 data.\n",
      "Loaded F11 data.\n",
      "Loaded F11_p1 data.\n",
      "Loaded G00 data.\n",
      "Loaded G00_p1 data.\n",
      "Loaded G01 data.\n",
      "Loaded G02 data.\n",
      "Loaded G03 data.\n",
      "Loaded G04 data.\n",
      "Loaded G05 data.\n",
      "Loaded G06 data.\n",
      "Loaded G07 data.\n",
      "Loaded G07_p1 data.\n",
      "Loaded G08 data.\n",
      "Loaded G09 data.\n",
      "Loaded G11 data.\n",
      "Loaded G11_p1 data.\n",
      "Loaded X00 data.\n",
      "Loaded X01 data.\n",
      "Loaded X02 data.\n",
      "Loaded X03 data.\n",
      "Loaded X04 data.\n",
      "Loaded X05 data.\n",
      "Loaded X06 data.\n",
      "Loaded X07 data.\n",
      "Loaded X08 data.\n",
      "Loaded X09 data.\n",
      "Loaded X10 data.\n",
      "Loaded X10_100 data.\n",
      "Loaded X11 data.\n",
      "Loaded X11_100 data.\n",
      "Loaded X11_1000 data.\n",
      "Loaded X11_10000 data.\n",
      "Loaded X11_std0100 data.\n",
      "Loaded X11_std0125 data.\n",
      "Loaded X11_std0200 data.\n",
      "Loaded X11_std0300 data.\n",
      "Loaded X11_std1000 data.\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "for file_name in os.listdir(data_path):\n",
    "    if file_name[-len(data_ext):] == data_ext:\n",
    "        \n",
    "        var = file_name[:-len(data_ext)]\n",
    "        var_data = np.loadtxt(os.path.join(data_path, file_name))\n",
    "        if len(var_data.shape) == 1:\n",
    "            var_data = var_data.reshape(-1,1)\n",
    "        data[var] = var_data\n",
    "\n",
    "        print(f\"Loaded {var} data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded masks for X00 data.\n",
      "Loaded masks for X01 data.\n",
      "Loaded masks for X02 data.\n",
      "Loaded masks for X03 data.\n",
      "Loaded masks for X04 data.\n",
      "Loaded masks for X05 data.\n",
      "Loaded masks for X06 data.\n",
      "Loaded masks for X07 data.\n",
      "Loaded masks for X08 data.\n",
      "Loaded masks for X09 data.\n",
      "Loaded masks for X10 data.\n",
      "No masks found for X10_100 data.\n",
      "No masks found for X11 data.\n",
      "No masks found for X11_100 data.\n",
      "No masks found for X11_1000 data.\n",
      "No masks found for X11_10000 data.\n",
      "No masks found for X11_std0100 data.\n",
      "No masks found for X11_std0125 data.\n",
      "No masks found for X11_std0200 data.\n",
      "No masks found for X11_std0300 data.\n",
      "No masks found for X11_std1000 data.\n"
     ]
    }
   ],
   "source": [
    "mask_ext = \".mask\"\n",
    "\n",
    "masks = {}\n",
    "for var in data:\n",
    "    if var[0] == \"X\":\n",
    "        try:\n",
    "            masks[var] = joblib.load(os.path.join(data_path, var + mask_ext))\n",
    "            print(f\"Loaded masks for {var} data.\")\n",
    "        except:\n",
    "            print(f\"No masks found for {var} data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8.2: Run PySR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(X, y):\n",
    "\n",
    "    model = PySRRegressor(\n",
    "        procs=4,\n",
    "        populations=30,\n",
    "        niterations=30,\n",
    "        maxsize=20,\n",
    "        binary_operators=[\"plus\", \"sub\", \"mult\"],\n",
    "        unary_operators=[\"sin\", \"cos\"], # \"exp\", \"log_abs\"      \n",
    "        model_selection=\"best\",\n",
    "        verbosity=0\n",
    "    )\n",
    "\n",
    "    model.fit(X, y)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"models\"\n",
    "model_name = \"pysr_models_1k_preds.pkl\"\n",
    "\n",
    "try:\n",
    "    models = joblib.load(os.path.join(model_path, model_name))\n",
    "except:\n",
    "    models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vars = sorted([k for k in data.keys() if k[0] == \"F\" and k not in models])\n",
    "vars = [\"F11_p1\"]\n",
    "\n",
    "for var in vars:\n",
    "\n",
    "    # get target dimensions\n",
    "    f_dim = data[var].shape[1]\n",
    "\n",
    "    # get input variables\n",
    "    g_var = \"G\" + var[1:]\n",
    "    x_var = \"X\" + var[1:].split('_')[0]\n",
    "\n",
    "    # get training mask\n",
    "    try:\n",
    "        mask = masks[x_var][\"train\"]\n",
    "    except:\n",
    "        mask = np.full(data[x_var].shape[0], True)\n",
    "\n",
    "    models[var] = {g_var: [], x_var: []}\n",
    "    for i in range(f_dim):\n",
    "\n",
    "        # get target data\n",
    "        y = data[var][mask,i]\n",
    "\n",
    "        # learn f(x)\n",
    "        print(f\"Learning {var}_{i}({g_var}).\")\n",
    "        X = data[g_var][mask]\n",
    "        models[var][g_var].append(get_model(X, y))\n",
    "\n",
    "        joblib.dump(models, os.path.join(model_path, model_name))\n",
    "    \n",
    "        # learn f(g(x))\n",
    "        print(f\"Learning {var}_{i}({x_var}).\")\n",
    "        X = data[x_var][mask]\n",
    "        models[var][x_var].append(get_model(X, y))\n",
    "\n",
    "        joblib.dump(models, os.path.join(model_path, model_name))\n",
    "\n",
    "    # get target dimensions\n",
    "    g_dim = data[g_var].shape[1]\n",
    "\n",
    "    models[g_var] = {x_var: []}\n",
    "    for i in range(g_dim):\n",
    "\n",
    "        # get target data\n",
    "        y = data[g_var][mask,i]\n",
    "   \n",
    "        # learn g(x)\n",
    "        print(f\"Learning {g_var}_{i}({x_var}).\")\n",
    "        X = data[x_var][mask]\n",
    "        models[g_var][x_var].append(get_model(X, y))\n",
    "\n",
    "        joblib.dump(models, os.path.join(model_path, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_name = \"hall_of_fame_\"\n",
    "\n",
    "for f in os.listdir():\n",
    "    if del_name in f:\n",
    "        os.remove(f)\n",
    "        print(f\"Deleted {f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8.3: Check discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_eps = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d_var in models:\n",
    "    for i_var in models[d_var]:\n",
    "        for m, model in enumerate(models[d_var][i_var]):\n",
    "            best = model.get_best()\n",
    "            print(f\"{d_var}_{m}({i_var}): {best.loss:.2e} - [{(' ','X')[best.loss < disc_eps]}] - {best.equation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8.4: Get full model and optimize constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_var = \"F11_p1\"\n",
    "l_var = \"G11_p1\"\n",
    "i_var = \"X11\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num2symbols(expr):\n",
    "    \n",
    "    w = sympy.Wild(\"w\", properties=[lambda t: isinstance(t, sympy.Float)])\n",
    "    n = expr.find(w)\n",
    "    \n",
    "    alphabet = [f\"p{p}\" for p in range(len(n))]\n",
    "    s = sympy.symbols(\" \".join(alphabet[:len(n)]))\n",
    "    \n",
    "    d = {k: v for k, v in zip(n, s)}\n",
    "    \n",
    "    return expr.subs(d), [float(k) for k in d]\n",
    "\n",
    "def optimize_eq(eq, inits, in_data, target_data):\n",
    "\n",
    "    i_syms = [f\"x{i}\" for i in range(in_data.shape[1])]\n",
    "    \n",
    "    def opt_fun(p):\n",
    "        opt_eq = eq.subs({f\"p{i}\": p[i] for i in range(len(p))})\n",
    "        return np.mean((sympy.lambdify(i_syms, opt_eq, modules='numpy')(*list(in_data.T)) - target_data)**2)\n",
    "    \n",
    "    res = optimize.minimize(opt_fun, inits, method=\"BFGS\")\n",
    "    opt_eq = eq.subs({f\"p{i}\": res.x[i] for i in range(len(res.x))})\n",
    "        \n",
    "    return opt_eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_eqs = []\n",
    "l_syms = []\n",
    "\n",
    "for m, model in enumerate(models[l_var][i_var]):\n",
    "    l_eqs.append(model.get_best().sympy_format)\n",
    "    l_syms.append(sympy.Symbol(f'x{m}'))\n",
    "    \n",
    "    print(model.get_best().equation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_eqs = []\n",
    "\n",
    "for model in models[d_var][l_var]:\n",
    "    f_eqs.append(model.get_best().sympy_format.subs(dict(zip(l_syms, l_eqs))))\n",
    "    \n",
    "print(f_eqs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"2.7*x0**2 + 4.5*x0*x1 + 5.0*cos(3.0*x1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f, f_eq in enumerate(f_eqs):\n",
    "    \n",
    "    p_eq, inits = num2symbols(f_eq)\n",
    "    print(p_eq)\n",
    "    \n",
    "    t_var = d_var.split('_')[0]\n",
    "    o_eq = optimize_eq(p_eq, inits, data[i_var], data[t_var][:,f])\n",
    "    print(o_eq)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "540f5367292c701f747780e6da702d3852f1c7c25c6067d18f36ab6562a2dcf2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
